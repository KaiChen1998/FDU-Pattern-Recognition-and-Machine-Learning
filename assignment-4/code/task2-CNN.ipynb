{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastNLP\n",
    "from fastNLP.io.dataset_loader import CSVLoader\n",
    "from fastNLP import Batch\n",
    "from fastNLP import Vocabulary\n",
    "from fastNLP import RandomSampler, SequentialSampler\n",
    "from fastNLP.io.embed_loader import EmbedLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1. Text classification using CNN with random word embedding\n",
    "### 1. Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda:  True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epoch = 5\n",
    "num_kernel = 128\n",
    "dropout_rate = 0.5\n",
    "use_pretrain = 0\n",
    "freeze_pretrain = 1\n",
    "embed_path = 'data/glove.6B.100d.txt'\n",
    "embedding_size = 100\n",
    "\n",
    "loss_history = []\n",
    "load_address = None\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: \", use_cuda)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(x):\n",
    "    if(x == ' '):\n",
    "        return [' ']\n",
    "    else:\n",
    "        return x.lower().split()\n",
    "\n",
    "def load_data(path, is_train = 0):\n",
    "    loader = CSVLoader(sep='\\t')\n",
    "    dataset = loader.load(path)\n",
    "    dataset.delete_field('SentenceId')\n",
    "    dataset.delete_field('PhraseId')\n",
    "    \n",
    "    dataset.apply(lambda x: get_word(x['Phrase']), new_field_name = 'words', is_input = True)\n",
    "    dataset.apply(lambda x: len(x['words']), new_field_name = \"length\", is_input = True)\n",
    "    dataset.delete_field('Phrase')\n",
    "    if(is_train):\n",
    "        dataset.apply(lambda x: int(x['Sentiment']), new_field_name = \"Sentiment\")\n",
    "        dataset.set_target('Sentiment')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size:  140454\n",
      "val_dataset size:  15606\n",
      "test_dataset size:  66292\n"
     ]
    }
   ],
   "source": [
    "# 1. get dataset\n",
    "dataset = load_data('data/train.tsv', 1)\n",
    "train_dataset, val_dataset = dataset.split(0.1)\n",
    "test_dataset = load_data('data/test.tsv', 0)\n",
    "print(\"train_dataset size: \", train_dataset.get_length())\n",
    "print(\"val_dataset size: \", val_dataset.get_length())\n",
    "print(\"test_dataset size: \", test_dataset.get_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size:  16507\n"
     ]
    }
   ],
   "source": [
    "# 2. get vocabulary\n",
    "if(use_pretrain):\n",
    "    loader = EmbedLoader()\n",
    "    # 同时fastNLP随机初始化了<pad>&<unk>的embedding\n",
    "    pre_embed, vocab = loader.load_without_vocab(embed_path, normalize = False)\n",
    "    embeddig_size = pre_embed.shape[1]\n",
    "else:\n",
    "    vocab = Vocabulary(min_freq=2).from_dataset(dataset, field_name='words')\n",
    "print(\"vocabulary size: \", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. word to index\n",
    "vocab.index_dataset(train_dataset, field_name='words',new_field_name='words')\n",
    "vocab.index_dataset(val_dataset, field_name='words',new_field_name='words')\n",
    "vocab.index_dataset(test_dataset, field_name='words',new_field_name='words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embedding_size, padding_idx = vocab['<pad>'])\n",
    "        if(use_pretrain):\n",
    "            self.embedding.from_pretrained(torch.Tensor(pre_embed), freeze = bool(freeze_pretrain))\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = num_kernel, kernel_size = (2, embedding_size))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 1, out_channels = num_kernel, kernel_size = (3, embedding_size))\n",
    "        self.conv3 = nn.Conv2d(in_channels = 1, out_channels = num_kernel, kernel_size = (4, embedding_size))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.AdaptiveMaxPool2d(1)\n",
    "        self.dropout = nn.Dropout(p = dropout_rate)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_kernel * 3, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        N = x.shape[0]\n",
    "        x = self.embedding(x) # [N, T, E]\n",
    "        x = x.view(N, 1, x.shape[1], x.shape[2])\n",
    "        conv1 = self.pooling(self.relu(self.conv1(x))).view((N, -1))\n",
    "        conv2 = self.pooling(self.relu(self.conv2(x))).view((N, -1))\n",
    "        conv3 = self.pooling(self.relu(self.conv3(x))).view((N, -1))\n",
    "        x = torch.cat((conv1, conv2, conv3), dim = 1)\n",
    "        x = self.dropout(x)\n",
    "        score = self.classifier(x)\n",
    "        return score\n",
    "    \n",
    "model = CNN()\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "if(load_address is not None):\n",
    "    model = torch.load(load_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_modules of CNN(\n",
      "  (embedding): Embedding(16507, 100, padding_idx=0)\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(2, 100), stride=(1, 1))\n",
      "  (conv2): Conv2d(1, 128, kernel_size=(3, 100), stride=(1, 1))\n",
      "  (conv3): Conv2d(1, 128, kernel_size=(4, 100), stride=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (pooling): AdaptiveMaxPool2d(output_size=1)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=5, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.named_modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_status(training):\n",
    "    if(training):\n",
    "        return 'model is in training'\n",
    "    else:\n",
    "        return 'model is in testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(batch_x, batch_y, is_train = 1):\n",
    "    x = batch_x['words']\n",
    "    lengths = batch_x['length']\n",
    "    index = torch.argsort(lengths, descending = True)\n",
    "    x = x[index].to(device)\n",
    "    lengths = lengths[index].to(device)\n",
    "    if(is_train):\n",
    "        y = batch_y['Sentiment']\n",
    "        y = y[index].to(device)\n",
    "        return x, lengths, y\n",
    "    else:\n",
    "        return x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    print(model_status(model.training))\n",
    "    num_correct = torch.tensor(0.0)\n",
    "    num_sample = torch.tensor(0.0)\n",
    "    for batch_x, batch_y in Batch(dataset, sampler = SequentialSampler(), batch_size = batch_size):\n",
    "        x, lengths, y = pack(batch_x, batch_y)\n",
    "        score = model(x, lengths)\n",
    "        y_predict = torch.argmax(score, dim = 1)\n",
    "        num_correct += torch.sum(y_predict == y)\n",
    "        num_sample += x.shape[0]\n",
    "    return 1.0 * num_correct / num_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 start\n",
      "model is in training\n",
      "Epoch: 0 finish\n",
      "model is in testing\n",
      "Epoch: 0, loss: 26.2403564453125, accu: 0.17000000178813934\n",
      "\n",
      "Epoch: 1 start\n",
      "model is in training\n",
      "Epoch: 1 finish\n",
      "model is in testing\n",
      "Epoch: 1, loss: 23.70697021484375, accu: 0.38999998569488525\n",
      "\n",
      "Epoch: 2 start\n",
      "model is in training\n",
      "Epoch: 2 finish\n",
      "model is in testing\n",
      "Epoch: 2, loss: 22.708452224731445, accu: 0.47999998927116394\n",
      "\n",
      "Epoch: 3 start\n",
      "model is in training\n",
      "Epoch: 3 finish\n",
      "model is in testing\n",
      "Epoch: 3, loss: 22.393625259399414, accu: 0.5\n",
      "\n",
      "Epoch: 4 start\n",
      "model is in training\n",
      "Epoch: 4 finish\n",
      "model is in testing\n",
      "Epoch: 4, loss: 21.850229263305664, accu: 0.47999998927116394\n",
      "\n",
      "Epoch: 5 start\n",
      "model is in training\n",
      "Epoch: 5 finish\n",
      "model is in testing\n",
      "Epoch: 5, loss: 21.4749698638916, accu: 0.5\n",
      "\n",
      "Epoch: 6 start\n",
      "model is in training\n",
      "Epoch: 6 finish\n",
      "model is in testing\n",
      "Epoch: 6, loss: 21.393253326416016, accu: 0.5\n",
      "\n",
      "Epoch: 7 start\n",
      "model is in training\n",
      "Epoch: 7 finish\n",
      "model is in testing\n",
      "Epoch: 7, loss: 20.658212661743164, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 8 start\n",
      "model is in training\n",
      "Epoch: 8 finish\n",
      "model is in testing\n",
      "Epoch: 8, loss: 20.809194564819336, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 9 start\n",
      "model is in training\n",
      "Epoch: 9 finish\n",
      "model is in testing\n",
      "Epoch: 9, loss: 20.33799934387207, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 10 start\n",
      "model is in training\n",
      "Epoch: 10 finish\n",
      "model is in testing\n",
      "Epoch: 10, loss: 19.88896369934082, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 11 start\n",
      "model is in training\n",
      "Epoch: 11 finish\n",
      "model is in testing\n",
      "Epoch: 11, loss: 19.567073822021484, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 12 start\n",
      "model is in training\n",
      "Epoch: 12 finish\n",
      "model is in testing\n",
      "Epoch: 12, loss: 19.330541610717773, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 13 start\n",
      "model is in training\n",
      "Epoch: 13 finish\n",
      "model is in testing\n",
      "Epoch: 13, loss: 19.41583251953125, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 14 start\n",
      "model is in training\n",
      "Epoch: 14 finish\n",
      "model is in testing\n",
      "Epoch: 14, loss: 19.131315231323242, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 15 start\n",
      "model is in training\n",
      "Epoch: 15 finish\n",
      "model is in testing\n",
      "Epoch: 15, loss: 18.637235641479492, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 16 start\n",
      "model is in training\n",
      "Epoch: 16 finish\n",
      "model is in testing\n",
      "Epoch: 16, loss: 18.30670166015625, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 17 start\n",
      "model is in training\n",
      "Epoch: 17 finish\n",
      "model is in testing\n",
      "Epoch: 17, loss: 18.053430557250977, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 18 start\n",
      "model is in training\n",
      "Epoch: 18 finish\n",
      "model is in testing\n",
      "Epoch: 18, loss: 17.894765853881836, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 19 start\n",
      "model is in training\n",
      "Epoch: 19 finish\n",
      "model is in testing\n",
      "Epoch: 19, loss: 17.605266571044922, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 20 start\n",
      "model is in training\n",
      "Epoch: 20 finish\n",
      "model is in testing\n",
      "Epoch: 20, loss: 17.737972259521484, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 21 start\n",
      "model is in training\n",
      "Epoch: 21 finish\n",
      "model is in testing\n",
      "Epoch: 21, loss: 17.37977409362793, accu: 0.5\n",
      "\n",
      "Epoch: 22 start\n",
      "model is in training\n",
      "Epoch: 22 finish\n",
      "model is in testing\n",
      "Epoch: 22, loss: 16.966039657592773, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 23 start\n",
      "model is in training\n",
      "Epoch: 23 finish\n",
      "model is in testing\n",
      "Epoch: 23, loss: 16.726367950439453, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 24 start\n",
      "model is in training\n",
      "Epoch: 24 finish\n",
      "model is in testing\n",
      "Epoch: 24, loss: 16.610088348388672, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 25 start\n",
      "model is in training\n",
      "Epoch: 25 finish\n",
      "model is in testing\n",
      "Epoch: 25, loss: 16.186893463134766, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 26 start\n",
      "model is in training\n",
      "Epoch: 26 finish\n",
      "model is in testing\n",
      "Epoch: 26, loss: 15.958735466003418, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 27 start\n",
      "model is in training\n",
      "Epoch: 27 finish\n",
      "model is in testing\n",
      "Epoch: 27, loss: 15.817170143127441, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 28 start\n",
      "model is in training\n",
      "Epoch: 28 finish\n",
      "model is in testing\n",
      "Epoch: 28, loss: 15.246009826660156, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 29 start\n",
      "model is in training\n",
      "Epoch: 29 finish\n",
      "model is in testing\n",
      "Epoch: 29, loss: 15.412792205810547, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 30 start\n",
      "model is in training\n",
      "Epoch: 30 finish\n",
      "model is in testing\n",
      "Epoch: 30, loss: 14.554518699645996, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 31 start\n",
      "model is in training\n",
      "Epoch: 31 finish\n",
      "model is in testing\n",
      "Epoch: 31, loss: 14.992596626281738, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 32 start\n",
      "model is in training\n",
      "Epoch: 32 finish\n",
      "model is in testing\n",
      "Epoch: 32, loss: 14.656672477722168, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 33 start\n",
      "model is in training\n",
      "Epoch: 33 finish\n",
      "model is in testing\n",
      "Epoch: 33, loss: 14.378957748413086, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 34 start\n",
      "model is in training\n",
      "Epoch: 34 finish\n",
      "model is in testing\n",
      "Epoch: 34, loss: 14.374566078186035, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 35 start\n",
      "model is in training\n",
      "Epoch: 35 finish\n",
      "model is in testing\n",
      "Epoch: 35, loss: 13.88920783996582, accu: 0.5\n",
      "\n",
      "Epoch: 36 start\n",
      "model is in training\n",
      "Epoch: 36 finish\n",
      "model is in testing\n",
      "Epoch: 36, loss: 13.605059623718262, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 37 start\n",
      "model is in training\n",
      "Epoch: 37 finish\n",
      "model is in testing\n",
      "Epoch: 37, loss: 13.646273612976074, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 38 start\n",
      "model is in training\n",
      "Epoch: 38 finish\n",
      "model is in testing\n",
      "Epoch: 38, loss: 13.49075698852539, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 39 start\n",
      "model is in training\n",
      "Epoch: 39 finish\n",
      "model is in testing\n",
      "Epoch: 39, loss: 13.034456253051758, accu: 0.5\n",
      "\n",
      "Epoch: 40 start\n",
      "model is in training\n",
      "Epoch: 40 finish\n",
      "model is in testing\n",
      "Epoch: 40, loss: 12.798952102661133, accu: 0.5\n",
      "\n",
      "Epoch: 41 start\n",
      "model is in training\n",
      "Epoch: 41 finish\n",
      "model is in testing\n",
      "Epoch: 41, loss: 12.415641784667969, accu: 0.5\n",
      "\n",
      "Epoch: 42 start\n",
      "model is in training\n",
      "Epoch: 42 finish\n",
      "model is in testing\n",
      "Epoch: 42, loss: 12.448023796081543, accu: 0.5\n",
      "\n",
      "Epoch: 43 start\n",
      "model is in training\n",
      "Epoch: 43 finish\n",
      "model is in testing\n",
      "Epoch: 43, loss: 12.232973098754883, accu: 0.5\n",
      "\n",
      "Epoch: 44 start\n",
      "model is in training\n",
      "Epoch: 44 finish\n",
      "model is in testing\n",
      "Epoch: 44, loss: 11.99008846282959, accu: 0.5\n",
      "\n",
      "Epoch: 45 start\n",
      "model is in training\n",
      "Epoch: 45 finish\n",
      "model is in testing\n",
      "Epoch: 45, loss: 11.74459171295166, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 46 start\n",
      "model is in training\n",
      "Epoch: 46 finish\n",
      "model is in testing\n",
      "Epoch: 46, loss: 11.590271949768066, accu: 0.5\n",
      "\n",
      "Epoch: 47 start\n",
      "model is in training\n",
      "Epoch: 47 finish\n",
      "model is in testing\n",
      "Epoch: 47, loss: 11.344278335571289, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 48 start\n",
      "model is in training\n",
      "Epoch: 48 finish\n",
      "model is in testing\n",
      "Epoch: 48, loss: 11.136280059814453, accu: 0.5\n",
      "\n",
      "Epoch: 49 start\n",
      "model is in training\n",
      "Epoch: 49 finish\n",
      "model is in testing\n",
      "Epoch: 49, loss: 11.07951831817627, accu: 0.5\n",
      "\n",
      "Epoch: 50 start\n",
      "model is in training\n",
      "Epoch: 50 finish\n",
      "model is in testing\n",
      "Epoch: 50, loss: 11.077964782714844, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 51 start\n",
      "model is in training\n",
      "Epoch: 51 finish\n",
      "model is in testing\n",
      "Epoch: 51, loss: 10.566064834594727, accu: 0.5\n",
      "\n",
      "Epoch: 52 start\n",
      "model is in training\n",
      "Epoch: 52 finish\n",
      "model is in testing\n",
      "Epoch: 52, loss: 10.572604179382324, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 53 start\n",
      "model is in training\n",
      "Epoch: 53 finish\n",
      "model is in testing\n",
      "Epoch: 53, loss: 10.292353630065918, accu: 0.5\n",
      "\n",
      "Epoch: 54 start\n",
      "model is in training\n",
      "Epoch: 54 finish\n",
      "model is in testing\n",
      "Epoch: 54, loss: 10.308796882629395, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 55 start\n",
      "model is in training\n",
      "Epoch: 55 finish\n",
      "model is in testing\n",
      "Epoch: 55, loss: 9.84868049621582, accu: 0.5\n",
      "\n",
      "Epoch: 56 start\n",
      "model is in training\n",
      "Epoch: 56 finish\n",
      "model is in testing\n",
      "Epoch: 56, loss: 10.07863998413086, accu: 0.5\n",
      "\n",
      "Epoch: 57 start\n",
      "model is in training\n",
      "Epoch: 57 finish\n",
      "model is in testing\n",
      "Epoch: 57, loss: 9.745741844177246, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 58 start\n",
      "model is in training\n",
      "Epoch: 58 finish\n",
      "model is in testing\n",
      "Epoch: 58, loss: 9.62807846069336, accu: 0.5\n",
      "\n",
      "Epoch: 59 start\n",
      "model is in training\n",
      "Epoch: 59 finish\n",
      "model is in testing\n",
      "Epoch: 59, loss: 9.528605461120605, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 60 start\n",
      "model is in training\n",
      "Epoch: 60 finish\n",
      "model is in testing\n",
      "Epoch: 60, loss: 9.257226943969727, accu: 0.5\n",
      "\n",
      "Epoch: 61 start\n",
      "model is in training\n",
      "Epoch: 61 finish\n",
      "model is in testing\n",
      "Epoch: 61, loss: 9.131976127624512, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 62 start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is in training\n",
      "Epoch: 62 finish\n",
      "model is in testing\n",
      "Epoch: 62, loss: 8.616268157958984, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 63 start\n",
      "model is in training\n",
      "Epoch: 63 finish\n",
      "model is in testing\n",
      "Epoch: 63, loss: 8.686956405639648, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 64 start\n",
      "model is in training\n",
      "Epoch: 64 finish\n",
      "model is in testing\n",
      "Epoch: 64, loss: 8.793126106262207, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 65 start\n",
      "model is in training\n",
      "Epoch: 65 finish\n",
      "model is in testing\n",
      "Epoch: 65, loss: 8.425320625305176, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 66 start\n",
      "model is in training\n",
      "Epoch: 66 finish\n",
      "model is in testing\n",
      "Epoch: 66, loss: 8.301085472106934, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 67 start\n",
      "model is in training\n",
      "Epoch: 67 finish\n",
      "model is in testing\n",
      "Epoch: 67, loss: 8.036895751953125, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 68 start\n",
      "model is in training\n",
      "Epoch: 68 finish\n",
      "model is in testing\n",
      "Epoch: 68, loss: 7.841493129730225, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 69 start\n",
      "model is in training\n",
      "Epoch: 69 finish\n",
      "model is in testing\n",
      "Epoch: 69, loss: 7.891096591949463, accu: 0.5\n",
      "\n",
      "Epoch: 70 start\n",
      "model is in training\n",
      "Epoch: 70 finish\n",
      "model is in testing\n",
      "Epoch: 70, loss: 7.822032451629639, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 71 start\n",
      "model is in training\n",
      "Epoch: 71 finish\n",
      "model is in testing\n",
      "Epoch: 71, loss: 7.653470516204834, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 72 start\n",
      "model is in training\n",
      "Epoch: 72 finish\n",
      "model is in testing\n",
      "Epoch: 72, loss: 7.2576904296875, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 73 start\n",
      "model is in training\n",
      "Epoch: 73 finish\n",
      "model is in testing\n",
      "Epoch: 73, loss: 7.267057418823242, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 74 start\n",
      "model is in training\n",
      "Epoch: 74 finish\n",
      "model is in testing\n",
      "Epoch: 74, loss: 7.233896732330322, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 75 start\n",
      "model is in training\n",
      "Epoch: 75 finish\n",
      "model is in testing\n",
      "Epoch: 75, loss: 6.9530229568481445, accu: 0.5\n",
      "\n",
      "Epoch: 76 start\n",
      "model is in training\n",
      "Epoch: 76 finish\n",
      "model is in testing\n",
      "Epoch: 76, loss: 6.938694953918457, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 77 start\n",
      "model is in training\n",
      "Epoch: 77 finish\n",
      "model is in testing\n",
      "Epoch: 77, loss: 6.888974666595459, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 78 start\n",
      "model is in training\n",
      "Epoch: 78 finish\n",
      "model is in testing\n",
      "Epoch: 78, loss: 6.45503568649292, accu: 0.5\n",
      "\n",
      "Epoch: 79 start\n",
      "model is in training\n",
      "Epoch: 79 finish\n",
      "model is in testing\n",
      "Epoch: 79, loss: 6.816446781158447, accu: 0.5\n",
      "\n",
      "Epoch: 80 start\n",
      "model is in training\n",
      "Epoch: 80 finish\n",
      "model is in testing\n",
      "Epoch: 80, loss: 6.533793926239014, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 81 start\n",
      "model is in training\n",
      "Epoch: 81 finish\n",
      "model is in testing\n",
      "Epoch: 81, loss: 6.353662967681885, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 82 start\n",
      "model is in training\n",
      "Epoch: 82 finish\n",
      "model is in testing\n",
      "Epoch: 82, loss: 6.162328720092773, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 83 start\n",
      "model is in training\n",
      "Epoch: 83 finish\n",
      "model is in testing\n",
      "Epoch: 83, loss: 6.279860496520996, accu: 0.5\n",
      "\n",
      "Epoch: 84 start\n",
      "model is in training\n",
      "Epoch: 84 finish\n",
      "model is in testing\n",
      "Epoch: 84, loss: 6.052204132080078, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 85 start\n",
      "model is in training\n",
      "Epoch: 85 finish\n",
      "model is in testing\n",
      "Epoch: 85, loss: 5.974637508392334, accu: 0.5\n",
      "\n",
      "Epoch: 86 start\n",
      "model is in training\n",
      "Epoch: 86 finish\n",
      "model is in testing\n",
      "Epoch: 86, loss: 6.056745529174805, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 87 start\n",
      "model is in training\n",
      "Epoch: 87 finish\n",
      "model is in testing\n",
      "Epoch: 87, loss: 5.654758453369141, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 88 start\n",
      "model is in training\n",
      "Epoch: 88 finish\n",
      "model is in testing\n",
      "Epoch: 88, loss: 5.606688499450684, accu: 0.5\n",
      "\n",
      "Epoch: 89 start\n",
      "model is in training\n",
      "Epoch: 89 finish\n",
      "model is in testing\n",
      "Epoch: 89, loss: 5.412878513336182, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 90 start\n",
      "model is in training\n",
      "Epoch: 90 finish\n",
      "model is in testing\n",
      "Epoch: 90, loss: 5.52683162689209, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 91 start\n",
      "model is in training\n",
      "Epoch: 91 finish\n",
      "model is in testing\n",
      "Epoch: 91, loss: 5.338341236114502, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 92 start\n",
      "model is in training\n",
      "Epoch: 92 finish\n",
      "model is in testing\n",
      "Epoch: 92, loss: 5.272369384765625, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 93 start\n",
      "model is in training\n",
      "Epoch: 93 finish\n",
      "model is in testing\n",
      "Epoch: 93, loss: 5.266674995422363, accu: 0.49000000953674316\n",
      "\n",
      "Epoch: 94 start\n",
      "model is in training\n",
      "Epoch: 94 finish\n",
      "model is in testing\n",
      "Epoch: 94, loss: 5.133930683135986, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 95 start\n",
      "model is in training\n",
      "Epoch: 95 finish\n",
      "model is in testing\n",
      "Epoch: 95, loss: 4.656529426574707, accu: 0.5299999713897705\n",
      "\n",
      "Epoch: 96 start\n",
      "model is in training\n",
      "Epoch: 96 finish\n",
      "model is in testing\n",
      "Epoch: 96, loss: 5.025689125061035, accu: 0.5199999809265137\n",
      "\n",
      "Epoch: 97 start\n",
      "model is in training\n",
      "Epoch: 97 finish\n",
      "model is in testing\n",
      "Epoch: 97, loss: 4.76030158996582, accu: 0.5099999904632568\n",
      "\n",
      "Epoch: 98 start\n",
      "model is in training\n",
      "Epoch: 98 finish\n",
      "model is in testing\n",
      "Epoch: 98, loss: 4.597297668457031, accu: 0.5\n",
      "\n",
      "Epoch: 99 start\n",
      "model is in training\n",
      "Epoch: 99 finish\n",
      "model is in testing\n",
      "Epoch: 99, loss: 4.636590003967285, accu: 0.4699999988079071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataset, optimizer, num_epoch = 30):\n",
    "    loss_history = []\n",
    "    for i in range(num_epoch):\n",
    "        print(\"Epoch: {0} start\".format(i))\n",
    "        model.train()\n",
    "        print(model_status(model.training))\n",
    "        losses = 0\n",
    "        for batch_x, batch_y in Batch(dataset, sampler = RandomSampler(), batch_size = batch_size):\n",
    "            x, lengths, y = pack(batch_x, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            score = model(x, lengths)\n",
    "            loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "            loss = loss_fn(score, y)\n",
    "            loss.backward()\n",
    "            losses += loss\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: {0} finish\".format(i))\n",
    "        loss_history.append(losses)\n",
    "        acc = predict(model, val_dataset[0:100])\n",
    "        print(\"Epoch: {0}, loss: {1}, accu: {2}\\n\".format(i, losses, acc))\n",
    "    return loss_history\n",
    "\n",
    "loss_history_new = train(model, train_dataset[0:1000], optimizer, num_epoch = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(plt):\n",
    "    plt.title(\"training loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(range(len(loss_history)), loss_history)\n",
    "    return plt\n",
    "\n",
    "loss_history += loss_history_new\n",
    "plt.figure(0)\n",
    "plot(plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to generate result\n",
      "model is in testing\n"
     ]
    }
   ],
   "source": [
    "def get_answer(model, dataset):\n",
    "    answer = []\n",
    "    model.eval()\n",
    "    print(\"start to generate result\")\n",
    "    print(model_status(model.training))\n",
    "    for batch_x, batch_y in Batch(dataset, sampler = SequentialSampler(), batch_size = batch_size):\n",
    "        x, lengths = pack(batch_x, batch_y, 0)\n",
    "        score = model(x, lengths)\n",
    "        y_predict = torch.argmax(score, dim = 1).cpu().numpy()\n",
    "        answer += list(y_predict)\n",
    "    index = [a + 156061 for a in range(len(answer))]\n",
    "    dataframe = pd.DataFrame({'PhraseId':index, 'Sentiment':answer})\n",
    "    name = \"result/CNN_pretrain\" + str(use_pretrain) + \"_freeze\" + str(freeze_pretrain) + \"_kernel\" + str(num_kernel) + \"dropouot\" + str(dropout_rate) + \"_random_batch_size\" + str(batch_size) + \"_lr\" + str(learning_rate) + \"_epoch\" + str(num_epoch) + \"_embedding\" + str(embedding_size)+\".csv\"\n",
    "    dataframe.to_csv(name,index=False,sep=',')\n",
    "    return answer\n",
    "\n",
    "answer = get_answer(model, test_dataset[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
